{"docstore/metadata": {"c7e602c7-21f4-42be-b090-1c505d9c6852": {"doc_hash": "d9fd348fca2075d4e44d91069d021731324c67feb57fafa5d5f6bcb1377aea8b"}, "f0eb2541-6b52-4263-8ce4-333938346100": {"doc_hash": "70842113168cebf420ee5a2a99593f13074589c84e6550f88a802ac7394e10e9", "ref_doc_id": "c7e602c7-21f4-42be-b090-1c505d9c6852"}, "28a38c59-4b89-4ccf-871e-3487033d0bbf": {"doc_hash": "322e62c1437f5421f1cc70eb67ddff5d410275712878266b23e3b32b41126682", "ref_doc_id": "c7e602c7-21f4-42be-b090-1c505d9c6852"}, "07a28afc-d901-4848-9b14-cdf6de49012b": {"doc_hash": "9ed7b517f0356dec45742b22d67bcc645024b7f0cf090e831af1d61fd96cc9ff", "ref_doc_id": "c7e602c7-21f4-42be-b090-1c505d9c6852"}, "25797184-7927-40c4-afd4-54c5144b48cb": {"doc_hash": "7a46f48dfeae5e7542b47da5201a5c9ee5b5aa70f2af074f9fd65715ab1a9c6f", "ref_doc_id": "c7e602c7-21f4-42be-b090-1c505d9c6852"}, "99f6dfcb-d76b-4860-a8bf-1e57e9ae8397": {"doc_hash": "7d0e30b667659f1c59679ca0290d3104250073bc09ba1f1a0a2f6008bacfa923", "ref_doc_id": "c7e602c7-21f4-42be-b090-1c505d9c6852"}, "87b55f54-5671-4e5d-a416-d0a1c5e4cc9d": {"doc_hash": "bd308a7e4bf07aa84457da4958c8b7850ad5486f737d0609356809637b27400e", "ref_doc_id": "c7e602c7-21f4-42be-b090-1c505d9c6852"}, "7e0e26a6-f2d1-4b62-b721-272dd96ac8e3": {"doc_hash": "6282ac5ab3d394839514bc648e9ca4b9611eb12ba72d79a6acb1fade0d80e1fd", "ref_doc_id": "c7e602c7-21f4-42be-b090-1c505d9c6852"}, "155f49bd-2e79-477b-a1be-0acd0deec3d7": {"doc_hash": "ee8fe8cf1a050caa32833429fecb1993d8fd7370c4b637358f1b03c5594f95bb", "ref_doc_id": "c7e602c7-21f4-42be-b090-1c505d9c6852"}, "6d5b137f-0b84-4aeb-aaac-40d44b998b6e": {"doc_hash": "db6978d6b5fedb408e4d5e45e6160fef55053c3a3c902147d1a336848a2a140d", "ref_doc_id": "c7e602c7-21f4-42be-b090-1c505d9c6852"}}, "docstore/data": {"f0eb2541-6b52-4263-8ce4-333938346100": {"__data__": {"id_": "f0eb2541-6b52-4263-8ce4-333938346100", "embedding": null, "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c7e602c7-21f4-42be-b090-1c505d9c6852", "node_type": "4", "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "hash": "d9fd348fca2075d4e44d91069d021731324c67feb57fafa5d5f6bcb1377aea8b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "28a38c59-4b89-4ccf-871e-3487033d0bbf", "node_type": "1", "metadata": {}, "hash": "322e62c1437f5421f1cc70eb67ddff5d410275712878266b23e3b32b41126682", "class_name": "RelatedNodeInfo"}}, "hash": "70842113168cebf420ee5a2a99593f13074589c84e6550f88a802ac7394e10e9", "text": "# -*- coding:utf-8 -*-\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom lib.utils import scaled_Laplacian, cheb_polynomial\n\n\nclass Spatial_Attention_layer(nn.Module):\n    '''\n    compute spatial attention scores\n    '''\n    def __init__(self, DEVICE, in_channels, num_of_vertices, num_of_timesteps):\n        super(Spatial_Attention_layer, self).__init__()\n        self.W1 = nn.Parameter(torch.FloatTensor(num_of_timesteps).to(DEVICE))\n        self.W2 = nn.Parameter(torch.FloatTensor(in_channels, num_of_timesteps).to(DEVICE))\n        self.W3 = nn.Parameter(torch.FloatTensor(in_channels).to(DEVICE))\n        self.bs = nn.Parameter(torch.FloatTensor(1, num_of_vertices, num_of_vertices).to(DEVICE))\n        self.Vs = nn.Parameter(torch.FloatTensor(num_of_vertices, num_of_vertices).to(DEVICE))\n\n\n    def forward(self, x):\n        '''\n        :param x: (batch_size, N, F_in, T)\n        :return: (B,N,N)\n        '''\n\n        lhs = torch.matmul(torch.matmul(x, self.W1), self.W2)  # (b,N,F,T)(T)->(b,N,F)(F,T)->(b,N,T)\n\n        rhs = torch.matmul(self.W3, x).transpose(-1, -2)  # (F)(b,N,F,T)->(b,N,T)->(b,T,N)\n\n        product = torch.matmul(lhs, rhs)  # (b,N,T)(b,T,N) -> (B, N, N)\n\n        S = torch.matmul(self.Vs, torch.sigmoid(product + self.bs))  # (N,N)(B, N, N)->(B,N,N)\n\n        S_normalized = F.softmax(S, dim=1)\n\n        return S_normalized\n\n\nclass cheb_conv_withSAt(nn.Module):\n    '''\n    K-order chebyshev graph convolution\n    '''\n\n    def __init__(self, K, cheb_polynomials, in_channels, out_channels):\n        '''\n        :param K: int\n        :param in_channles: int, num of channels in the input sequence\n        :param out_channels: int,", "start_char_idx": 0, "end_char_idx": 1678, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "28a38c59-4b89-4ccf-871e-3487033d0bbf": {"__data__": {"id_": "28a38c59-4b89-4ccf-871e-3487033d0bbf", "embedding": null, "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c7e602c7-21f4-42be-b090-1c505d9c6852", "node_type": "4", "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "hash": "d9fd348fca2075d4e44d91069d021731324c67feb57fafa5d5f6bcb1377aea8b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f0eb2541-6b52-4263-8ce4-333938346100", "node_type": "1", "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "hash": "70842113168cebf420ee5a2a99593f13074589c84e6550f88a802ac7394e10e9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "07a28afc-d901-4848-9b14-cdf6de49012b", "node_type": "1", "metadata": {}, "hash": "9ed7b517f0356dec45742b22d67bcc645024b7f0cf090e831af1d61fd96cc9ff", "class_name": "RelatedNodeInfo"}}, "hash": "322e62c1437f5421f1cc70eb67ddff5d410275712878266b23e3b32b41126682", "text": "class cheb_conv_withSAt(nn.Module):\n    '''\n    K-order chebyshev graph convolution\n    '''\n\n    def __init__(self, K, cheb_polynomials, in_channels, out_channels):\n        '''\n        :param K: int\n        :param in_channles: int, num of channels in the input sequence\n        :param out_channels: int, num of channels in the output sequence\n        '''\n        super(cheb_conv_withSAt, self).__init__()\n        self.K = K\n        self.cheb_polynomials = cheb_polynomials\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.DEVICE = cheb_polynomials[0].device\n        self.Theta = nn.ParameterList([nn.Parameter(torch.FloatTensor(in_channels, out_channels).to(self.DEVICE)) for _ in range(K)])\n\n    def forward(self, x, spatial_attention):\n        '''\n        Chebyshev graph convolution operation\n        :param x: (batch_size, N, F_in, T)\n        :return: (batch_size, N, F_out, T)\n        '''\n\n        batch_size, num_of_vertices, in_channels, num_of_timesteps = x.shape\n\n        outputs = []\n\n        for time_step in range(num_of_timesteps):\n\n            graph_signal = x[:, :, :, time_step]  # (b, N, F_in)\n\n            output = torch.zeros(batch_size, num_of_vertices, self.out_channels).to(self.DEVICE)  # (b, N, F_out)\n\n            for k in range(self.K):\n\n                T_k = self.cheb_polynomials[k]  # (N,N)\n\n                T_k_with_at = T_k.mul(spatial_attention)   # (N,N)*(N,N) = (N,N) \u591a\u884c\u548c\u4e3a1, \u6309\u7740\u5217\u8fdb\u884c\u5f52\u4e00\u5316\n\n                theta_k = self.Theta[k]  # (in_channel, out_channel)\n\n                rhs = T_k_with_at.permute(0, 2, 1).matmul(graph_signal)  # (N, N)(b, N, F_in) = (b, N,", "start_char_idx": 1375, "end_char_idx": 3010, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "07a28afc-d901-4848-9b14-cdf6de49012b": {"__data__": {"id_": "07a28afc-d901-4848-9b14-cdf6de49012b", "embedding": null, "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c7e602c7-21f4-42be-b090-1c505d9c6852", "node_type": "4", "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "hash": "d9fd348fca2075d4e44d91069d021731324c67feb57fafa5d5f6bcb1377aea8b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "28a38c59-4b89-4ccf-871e-3487033d0bbf", "node_type": "1", "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "hash": "322e62c1437f5421f1cc70eb67ddff5d410275712878266b23e3b32b41126682", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "25797184-7927-40c4-afd4-54c5144b48cb", "node_type": "1", "metadata": {}, "hash": "7a46f48dfeae5e7542b47da5201a5c9ee5b5aa70f2af074f9fd65715ab1a9c6f", "class_name": "RelatedNodeInfo"}}, "hash": "9ed7b517f0356dec45742b22d67bcc645024b7f0cf090e831af1d61fd96cc9ff", "text": ":, :, time_step]  # (b, N, F_in)\n\n            output = torch.zeros(batch_size, num_of_vertices, self.out_channels).to(self.DEVICE)  # (b, N, F_out)\n\n            for k in range(self.K):\n\n                T_k = self.cheb_polynomials[k]  # (N,N)\n\n                T_k_with_at = T_k.mul(spatial_attention)   # (N,N)*(N,N) = (N,N) \u591a\u884c\u548c\u4e3a1, \u6309\u7740\u5217\u8fdb\u884c\u5f52\u4e00\u5316\n\n                theta_k = self.Theta[k]  # (in_channel, out_channel)\n\n                rhs = T_k_with_at.permute(0, 2, 1).matmul(graph_signal)  # (N, N)(b, N, F_in) = (b, N, F_in) \u56e0\u4e3a\u662f\u5de6\u4e58\uff0c\u6240\u4ee5\u591a\u884c\u548c\u4e3a1\u53d8\u4e3a\u591a\u5217\u548c\u4e3a1\uff0c\u5373\u4e00\u884c\u4e4b\u548c\u4e3a1\uff0c\u8fdb\u884c\u5de6\u4e58\n\n                output = output + rhs.matmul(theta_k)  # (b, N, F_in)(F_in, F_out) = (b, N, F_out)\n\n            outputs.append(output.unsqueeze(-1))  # (b, N, F_out, 1)\n\n        return F.relu(torch.cat(outputs, dim=-1))  # (b, N, F_out, T)", "start_char_idx": 2497, "end_char_idx": 3291, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "25797184-7927-40c4-afd4-54c5144b48cb": {"__data__": {"id_": "25797184-7927-40c4-afd4-54c5144b48cb", "embedding": null, "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c7e602c7-21f4-42be-b090-1c505d9c6852", "node_type": "4", "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "hash": "d9fd348fca2075d4e44d91069d021731324c67feb57fafa5d5f6bcb1377aea8b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "07a28afc-d901-4848-9b14-cdf6de49012b", "node_type": "1", "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "hash": "9ed7b517f0356dec45742b22d67bcc645024b7f0cf090e831af1d61fd96cc9ff", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "99f6dfcb-d76b-4860-a8bf-1e57e9ae8397", "node_type": "1", "metadata": {}, "hash": "7d0e30b667659f1c59679ca0290d3104250073bc09ba1f1a0a2f6008bacfa923", "class_name": "RelatedNodeInfo"}}, "hash": "7a46f48dfeae5e7542b47da5201a5c9ee5b5aa70f2af074f9fd65715ab1a9c6f", "text": "\u6309\u7740\u5217\u8fdb\u884c\u5f52\u4e00\u5316\n\n                theta_k = self.Theta[k]  # (in_channel, out_channel)\n\n                rhs = T_k_with_at.permute(0, 2, 1).matmul(graph_signal)  # (N, N)(b, N, F_in) = (b, N, F_in) \u56e0\u4e3a\u662f\u5de6\u4e58\uff0c\u6240\u4ee5\u591a\u884c\u548c\u4e3a1\u53d8\u4e3a\u591a\u5217\u548c\u4e3a1\uff0c\u5373\u4e00\u884c\u4e4b\u548c\u4e3a1\uff0c\u8fdb\u884c\u5de6\u4e58\n\n                output = output + rhs.matmul(theta_k)  # (b, N, F_in)(F_in, F_out) = (b, N, F_out)\n\n            outputs.append(output.unsqueeze(-1))  # (b, N, F_out, 1)\n\n        return F.relu(torch.cat(outputs, dim=-1))  # (b, N, F_out, T)\n\n\nclass Temporal_Attention_layer(nn.Module):\n    def __init__(self, DEVICE, in_channels, num_of_vertices, num_of_timesteps):\n        super(Temporal_Attention_layer, self).__init__()\n        self.U1 = nn.Parameter(torch.FloatTensor(num_of_vertices).to(DEVICE))\n        self.U2 = nn.Parameter(torch.FloatTensor(in_channels, num_of_vertices).to(DEVICE))\n        self.U3 = nn.Parameter(torch.FloatTensor(in_channels).to(DEVICE))\n        self.be = nn.Parameter(torch.FloatTensor(1, num_of_timesteps, num_of_timesteps).to(DEVICE))\n        self.Ve = nn.Parameter(torch.FloatTensor(num_of_timesteps, num_of_timesteps).to(DEVICE))\n\n    def forward(self, x):\n        '''\n        :param x: (batch_size, N, F_in, T)\n        :return: (B, T, T)\n        '''\n        _, num_of_vertices, num_of_features, num_of_timesteps = x.shape\n\n        lhs = torch.matmul(torch.matmul(x.permute(0, 3, 2, 1), self.U1), self.U2)\n        # x:(B, N, F_in, T) -> (B, T, F_in, N)\n        # (B, T, F_in, N)(N) -> (B,T,F_in)\n        # (B,T,F_in)(F_in,N)->(B,T,N)\n\n        rhs = torch.matmul(self.U3, x)  # (F)(B,N,F,T)->(B, N, T)\n\n        product = torch.matmul(lhs, rhs)  # (B,T,N)(B,N,T)->(B,T,T)\n\n        E = torch.matmul(self.Ve, torch.sigmoid(product + self.be))  # (B, T, T)\n\n        E_normalized = F.softmax(E, dim=1)\n\n        return E_normalized", "start_char_idx": 2828, "end_char_idx": 4608, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "99f6dfcb-d76b-4860-a8bf-1e57e9ae8397": {"__data__": {"id_": "99f6dfcb-d76b-4860-a8bf-1e57e9ae8397", "embedding": null, "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c7e602c7-21f4-42be-b090-1c505d9c6852", "node_type": "4", "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "hash": "d9fd348fca2075d4e44d91069d021731324c67feb57fafa5d5f6bcb1377aea8b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "25797184-7927-40c4-afd4-54c5144b48cb", "node_type": "1", "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "hash": "7a46f48dfeae5e7542b47da5201a5c9ee5b5aa70f2af074f9fd65715ab1a9c6f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "87b55f54-5671-4e5d-a416-d0a1c5e4cc9d", "node_type": "1", "metadata": {}, "hash": "bd308a7e4bf07aa84457da4958c8b7850ad5486f737d0609356809637b27400e", "class_name": "RelatedNodeInfo"}}, "hash": "7d0e30b667659f1c59679ca0290d3104250073bc09ba1f1a0a2f6008bacfa923", "text": "class cheb_conv(nn.Module):\n    '''\n    K-order chebyshev graph convolution\n    '''\n\n    def __init__(self, K, cheb_polynomials, in_channels, out_channels):\n        '''\n        :param K: int\n        :param in_channles: int, num of channels in the input sequence\n        :param out_channels: int, num of channels in the output sequence\n        '''\n        super(cheb_conv, self).__init__()\n        self.K = K\n        self.cheb_polynomials = cheb_polynomials\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.DEVICE = cheb_polynomials[0].device\n        self.Theta = nn.ParameterList([nn.Parameter(torch.FloatTensor(in_channels, out_channels).to(self.DEVICE)) for _ in range(K)])\n\n    def forward(self, x):\n        '''\n        Chebyshev graph convolution operation\n        :param x: (batch_size, N, F_in, T)\n        :return: (batch_size, N, F_out, T)\n        '''\n\n        batch_size, num_of_vertices, in_channels, num_of_timesteps = x.shape\n\n        outputs = []\n\n        for time_step in range(num_of_timesteps):\n\n            graph_signal = x[:, :, :, time_step]  # (b, N, F_in)\n\n            output = torch.zeros(batch_size, num_of_vertices, self.out_channels).to(self.DEVICE)  # (b, N, F_out)\n\n            for k in range(self.K):\n\n                T_k = self.cheb_polynomials[k]  # (N,N)\n\n                theta_k = self.Theta[k]  # (in_channel, out_channel)\n\n                rhs = graph_signal.permute(0, 2, 1).matmul(T_k).permute(0, 2, 1)\n\n                output = output + rhs.matmul(theta_k)\n\n            outputs.append(output.unsqueeze(-1))\n\n        return F.relu(torch.cat(outputs, dim=-1))\n\n\nclass ASTGCN_block(nn.Module):\n\n    def __init__(self, DEVICE, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_of_vertices,", "start_char_idx": 4611, "end_char_idx": 6409, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "87b55f54-5671-4e5d-a416-d0a1c5e4cc9d": {"__data__": {"id_": "87b55f54-5671-4e5d-a416-d0a1c5e4cc9d", "embedding": null, "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c7e602c7-21f4-42be-b090-1c505d9c6852", "node_type": "4", "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "hash": "d9fd348fca2075d4e44d91069d021731324c67feb57fafa5d5f6bcb1377aea8b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "99f6dfcb-d76b-4860-a8bf-1e57e9ae8397", "node_type": "1", "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "hash": "7d0e30b667659f1c59679ca0290d3104250073bc09ba1f1a0a2f6008bacfa923", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7e0e26a6-f2d1-4b62-b721-272dd96ac8e3", "node_type": "1", "metadata": {}, "hash": "6282ac5ab3d394839514bc648e9ca4b9611eb12ba72d79a6acb1fade0d80e1fd", "class_name": "RelatedNodeInfo"}}, "hash": "bd308a7e4bf07aa84457da4958c8b7850ad5486f737d0609356809637b27400e", "text": "class ASTGCN_block(nn.Module):\n\n    def __init__(self, DEVICE, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_of_vertices, num_of_timesteps):\n        super(ASTGCN_block, self).__init__()\n        self.TAt = Temporal_Attention_layer(DEVICE, in_channels, num_of_vertices, num_of_timesteps)\n        self.SAt = Spatial_Attention_layer(DEVICE, in_channels, num_of_vertices, num_of_timesteps)\n        self.cheb_conv_SAt = cheb_conv_withSAt(K, cheb_polynomials, in_channels, nb_chev_filter)\n        self.time_conv = nn.Conv2d(nb_chev_filter, nb_time_filter, kernel_size=(1, 3), stride=(1, time_strides), padding=(0, 1))\n        self.residual_conv = nn.Conv2d(in_channels, nb_time_filter, kernel_size=(1, 1), stride=(1, time_strides))\n        self.ln = nn.LayerNorm(nb_time_filter)  #\u9700\u8981\u5c06channel\u653e\u5230\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\n\n    def forward(self, x):\n        '''\n        :param x: (batch_size, N, F_in, T)\n        :return: (batch_size, N, nb_time_filter, T)\n        '''\n        batch_size, num_of_vertices, num_of_features, num_of_timesteps = x.shape\n\n        # TAt\n        temporal_At = self.TAt(x)  # (b, T, T)\n\n        x_TAt = torch.matmul(x.reshape(batch_size, -1, num_of_timesteps), temporal_At).reshape(batch_size, num_of_vertices, num_of_features, num_of_timesteps)\n\n        # SAt\n        spatial_At = self.SAt(x_TAt)\n\n        # cheb gcn\n        spatial_gcn = self.cheb_conv_SAt(x, spatial_At)  # (b,N,F,T)\n        # spatial_gcn = self.cheb_conv(x)\n\n        # convolution along the time axis\n        time_conv_output = self.time_conv(spatial_gcn.permute(0, 2,", "start_char_idx": 6250, "end_char_idx": 7824, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7e0e26a6-f2d1-4b62-b721-272dd96ac8e3": {"__data__": {"id_": "7e0e26a6-f2d1-4b62-b721-272dd96ac8e3", "embedding": null, "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c7e602c7-21f4-42be-b090-1c505d9c6852", "node_type": "4", "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "hash": "d9fd348fca2075d4e44d91069d021731324c67feb57fafa5d5f6bcb1377aea8b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "87b55f54-5671-4e5d-a416-d0a1c5e4cc9d", "node_type": "1", "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "hash": "bd308a7e4bf07aa84457da4958c8b7850ad5486f737d0609356809637b27400e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "155f49bd-2e79-477b-a1be-0acd0deec3d7", "node_type": "1", "metadata": {}, "hash": "ee8fe8cf1a050caa32833429fecb1993d8fd7370c4b637358f1b03c5594f95bb", "class_name": "RelatedNodeInfo"}}, "hash": "6282ac5ab3d394839514bc648e9ca4b9611eb12ba72d79a6acb1fade0d80e1fd", "text": "N, nb_time_filter, T)\n        '''\n        batch_size, num_of_vertices, num_of_features, num_of_timesteps = x.shape\n\n        # TAt\n        temporal_At = self.TAt(x)  # (b, T, T)\n\n        x_TAt = torch.matmul(x.reshape(batch_size, -1, num_of_timesteps), temporal_At).reshape(batch_size, num_of_vertices, num_of_features, num_of_timesteps)\n\n        # SAt\n        spatial_At = self.SAt(x_TAt)\n\n        # cheb gcn\n        spatial_gcn = self.cheb_conv_SAt(x, spatial_At)  # (b,N,F,T)\n        # spatial_gcn = self.cheb_conv(x)\n\n        # convolution along the time axis\n        time_conv_output = self.time_conv(spatial_gcn.permute(0, 2, 1, 3))  # (b,N,F,T)->(b,F,N,T) \u7528(1,3)\u7684\u5377\u79ef\u6838\u53bb\u505a->(b,F,N,T)\n\n        # residual shortcut\n        x_residual = self.residual_conv(x.permute(0, 2, 1, 3))  # (b,N,F,T)->(b,F,N,T) \u7528(1,1)\u7684\u5377\u79ef\u6838\u53bb\u505a->(b,F,N,T)\n\n        x_residual = self.ln(F.relu(x_residual + time_conv_output).permute(0, 3, 2, 1)).permute(0, 2, 3, 1)\n        # (b,F,N,T)->(b,T,N,F) -ln-> (b,T,N,F)->(b,N,F,T)\n\n        return x_residual", "start_char_idx": 7194, "end_char_idx": 8213, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "155f49bd-2e79-477b-a1be-0acd0deec3d7": {"__data__": {"id_": "155f49bd-2e79-477b-a1be-0acd0deec3d7", "embedding": null, "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c7e602c7-21f4-42be-b090-1c505d9c6852", "node_type": "4", "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "hash": "d9fd348fca2075d4e44d91069d021731324c67feb57fafa5d5f6bcb1377aea8b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7e0e26a6-f2d1-4b62-b721-272dd96ac8e3", "node_type": "1", "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "hash": "6282ac5ab3d394839514bc648e9ca4b9611eb12ba72d79a6acb1fade0d80e1fd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6d5b137f-0b84-4aeb-aaac-40d44b998b6e", "node_type": "1", "metadata": {}, "hash": "db6978d6b5fedb408e4d5e45e6160fef55053c3a3c902147d1a336848a2a140d", "class_name": "RelatedNodeInfo"}}, "hash": "ee8fe8cf1a050caa32833429fecb1993d8fd7370c4b637358f1b03c5594f95bb", "text": "F,N,T) \u7528(1,3)\u7684\u5377\u79ef\u6838\u53bb\u505a->(b,F,N,T)\n\n        # residual shortcut\n        x_residual = self.residual_conv(x.permute(0, 2, 1, 3))  # (b,N,F,T)->(b,F,N,T) \u7528(1,1)\u7684\u5377\u79ef\u6838\u53bb\u505a->(b,F,N,T)\n\n        x_residual = self.ln(F.relu(x_residual + time_conv_output).permute(0, 3, 2, 1)).permute(0, 2, 3, 1)\n        # (b,F,N,T)->(b,T,N,F) -ln-> (b,T,N,F)->(b,N,F,T)\n\n        return x_residual\n\n\nclass ASTGCN_submodule(nn.Module):\n\n    def __init__(self, DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_for_predict, len_input, num_of_vertices):\n        '''\n        :param nb_block:\n        :param in_channels:\n        :param K:\n        :param nb_chev_filter:\n        :param nb_time_filter:\n        :param time_strides:\n        :param cheb_polynomials:\n        :param nb_predict_step:\n        '''\n\n        super(ASTGCN_submodule, self).__init__()\n\n        self.BlockList = nn.ModuleList([ASTGCN_block(DEVICE, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_of_vertices, len_input)])\n\n        self.BlockList.extend([ASTGCN_block(DEVICE, nb_time_filter, K, nb_chev_filter, nb_time_filter, 1, cheb_polynomials, num_of_vertices, len_input//time_strides) for _ in range(nb_block-1)])\n\n        self.final_conv = nn.Conv2d(int(len_input/time_strides), num_for_predict, kernel_size=(1, nb_time_filter))\n\n        self.DEVICE = DEVICE\n\n        self.to(DEVICE)\n\n    def forward(self, x):\n        '''\n        :param x: (B, N_nodes, F_in, T_in)\n        :return: (B, N_nodes, T_out)\n        '''\n        for block in self.BlockList:\n            x = block(x)\n\n        output = self.final_conv(x.permute(0, 3, 1, 2))[:, :, :, -1].permute(0, 2, 1)\n        # (b,N,F,T)->(b,T,N,F)-conv<1,F>->(b,c_out*T,N,1)->(b,c_out*T,N)->(b,N,T)\n\n        return output", "start_char_idx": 7849, "end_char_idx": 9643, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6d5b137f-0b84-4aeb-aaac-40d44b998b6e": {"__data__": {"id_": "6d5b137f-0b84-4aeb-aaac-40d44b998b6e", "embedding": null, "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c7e602c7-21f4-42be-b090-1c505d9c6852", "node_type": "4", "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "hash": "d9fd348fca2075d4e44d91069d021731324c67feb57fafa5d5f6bcb1377aea8b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "155f49bd-2e79-477b-a1be-0acd0deec3d7", "node_type": "1", "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}, "hash": "ee8fe8cf1a050caa32833429fecb1993d8fd7370c4b637358f1b03c5594f95bb", "class_name": "RelatedNodeInfo"}}, "hash": "db6978d6b5fedb408e4d5e45e6160fef55053c3a3c902147d1a336848a2a140d", "text": "def make_model(DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, adj_mx, num_for_predict, len_input, num_of_vertices):\n    '''\n\n    :param DEVICE:\n    :param nb_block:\n    :param in_channels:\n    :param K:\n    :param nb_chev_filter:\n    :param nb_time_filter:\n    :param time_strides:\n    :param cheb_polynomials:\n    :param nb_predict_step:\n    :param len_input\n    :return:\n    '''\n    L_tilde = scaled_Laplacian(adj_mx)\n    cheb_polynomials = [torch.from_numpy(i).type(torch.FloatTensor).to(DEVICE) for i in cheb_polynomial(L_tilde, K)]\n    model = ASTGCN_submodule(DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_for_predict, len_input, num_of_vertices)\n\n    for p in model.parameters():\n        if p.dim() > 1:\n            nn.init.xavier_uniform_(p)\n        else:\n            nn.init.uniform_(p)\n\n    return model", "start_char_idx": 9646, "end_char_idx": 10548, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"c7e602c7-21f4-42be-b090-1c505d9c6852": {"node_ids": ["f0eb2541-6b52-4263-8ce4-333938346100", "28a38c59-4b89-4ccf-871e-3487033d0bbf", "07a28afc-d901-4848-9b14-cdf6de49012b", "25797184-7927-40c4-afd4-54c5144b48cb", "99f6dfcb-d76b-4860-a8bf-1e57e9ae8397", "87b55f54-5671-4e5d-a416-d0a1c5e4cc9d", "7e0e26a6-f2d1-4b62-b721-272dd96ac8e3", "155f49bd-2e79-477b-a1be-0acd0deec3d7", "6d5b137f-0b84-4aeb-aaac-40d44b998b6e"], "metadata": {"filename": "D:\\Academy\\Federated-learning\\cloned-projects\\ASTGCN-2019-pytorch\\model\\ASTGCN_r - Copy.txt"}}}}